#!/usr/bin/env python
# encoding: utf-8

"""
Author: Rosen
Mail: rosenluov@gmail.com
File: es-agent.py
Created Time: 12/21/16 14:34
"""

from __future__ import print_function

import json
import logging
import os
import sys
import time
from logging.handlers import TimedRotatingFileHandler
from multiprocessing import Process, Queue
from traceback import print_exc

import requests
import statsd

from conf.settings import (
    traps1,
    traps2,
    GAUGE,
    COUNTER,
    pidfile,
    stderr,
    stdout,
    HOSTNAME,
    IP,
    PORT,
    STATSD_FILE,
    OPEN_FALCON,
    SEC_METRIC
)
from utils.common import load_yaml_data
from utils.daemonize import Daemon

"""
    The ElasticSearch-agent collects state information by
    calling the ElasticSearch API and sends it to StatsD and open-falcon.
"""

# log setting


log_formatter = logging.Formatter('%(asctime)s %(name)s: %(filename)s[line:%(lineno)d] %(levelname)s %(message)s')
# info log
es_logger_out = logging.getLogger('')
keep_out = TimedRotatingFileHandler(stdout, 'midnight', 1, 7)
keep_out.setFormatter(log_formatter)
es_logger_out.setLevel(logging.INFO)
es_logger_out.addHandler(keep_out)

q = Queue(10)


def load_statsd_conf(filename=None):
    data = load_yaml_data(filename)
    host = data.get('host', '')
    port = data.get('port', )
    return host, port


def load_falcon_conf(filename=None):
    data = load_yaml_data(filename)
    url = data.get('url', '')
    return url


def es_data(endpoint, metric, timestamp, value, counter_type, tags):
    structure = {
        'endpoint': endpoint,
        'metric': metric,
        'timestamp': timestamp,
        'step': 10,
        'value': value,
        'counterType': counter_type,
        'tags': tags
    }
    return structure


# read specified keys from json data
def get_keys(stats, traps, ts):
    stats_data_gauge = {}
    stats_data_timer = {}
    tags = ""
    falcon_data = []

    for key in traps:
        if key == 'status':
            value = stats.get(key, '')
            if value == 'green':
                stats[key] = 1
            elif value == 'yellow':
                stats[key] = 2
            elif value == 'red':
                stats[key] = 0

        c = key.split('.')
        s = stats
        while len(c):
            s = s.get(c.pop(0), {})

        if s == {}:
            continue

        metric = 'es.' + key
        if key in GAUGE:
            falcon_data.append(es_data(HOSTNAME, metric, ts, s, 'GAUGE', tags))
            stats_data_gauge[key] = s
        elif key in COUNTER:
            falcon_data.append(es_data(HOSTNAME, metric, ts, s, 'COUNTER', tags))
            stats_data_timer[key] = s

    return falcon_data, stats_data_gauge, stats_data_timer


class MyDaemon(Daemon):
    @staticmethod
    def run():
        es_logger_out.info("Daemon started with pid %d! \n", os.getpid())
        while True:
            if int(time.time()) % 10 == 0:
                p = Process(target=main)
                p.start()
                p.join()
                time.sleep(1)


def write_log(out=None, metrics=None):
    if out is None:
        out = []
    if metrics is None:
        metrics = []
    es_logger_out.info("Delivery %d metrics %s! \n", metrics, out)


def send_to_falcon(url=None, data=None):
    if data and url:
        res = requests.post(url, data=json.dumps(data))
        return res


def send_to_statsd(statsd_client=None, data=None, gauge=False, timer=False):
    try:
        if data and gauge:
            for k, v in data.items():
                metric = HOSTNAME + '.' + k
                statsd_client.gauge(metric, v)
        if data and timer:
            for k, v in data.items():
                metric = HOSTNAME + '.' + k
                statsd_client.gauge(metric, v)

    except Exception as e:
        es_logger_out.error(e)
        print_exc()


def timer_to_gauge(data=None):
    counter_stats_data = {}
    if not q.empty():
        es_logger_out.info('Get a message from the Queue.')
        old_stats_data = q.get()
        for k in data:
            counter_stats_data[k] = round((int(data[k]) - int(old_stats_data[k])) / 10, 2)
        return counter_stats_data
    else:
        es_logger_out.error('Queue is empty!')
        return data


def timer_to_timer_rate(data=None):
    sec_data = {}
    if data:
        for k, v in SEC_METRIC.items():
            key = k + '.sec'
            try:
                sec_data[key] = data[k] / data[v]
            except ZeroDivisionError:
                sec_data[key] = 0
        statsd_data_timer = dict(data, **sec_data)
        return statsd_data_timer
    else:
        es_logger_out.info('No timers data.')


def main():
    # load json data
    node = {}
    try:
        health_res = requests.get("http://{IP}:{PORT}/_cluster/health".format(IP=IP, PORT=PORT), timeout=10)
        stats_res = requests.get("http://{IP}:{PORT}/_nodes/_local/stats?all=true".format(IP=IP, PORT=PORT), timeout=10)
        data_time = int(time.time())
        health = health_res.json()
        stats = stats_res.json()
        # only for current node
        for node_id in stats.get('nodes', {}).keys():
            if stats['nodes'][node_id]['host'].startswith(IP):
                node = stats['nodes'][node_id]
                if len(sys.argv) == 1:
                    es_logger_out.error("node found")
    except requests.exceptions.ConnectTimeout as e:
        es_logger_out.error(e)
        print_exc()
        sys.exit(1)

    except Exception as e:
        es_logger_out.error(e + "and Unable to load JSON data!")
        print_exc()
        sys.exit(1)

    statsd_host, statsd_port = load_statsd_conf(STATSD_FILE)
    statsd_client = statsd.StatsClient(statsd_host, statsd_port, health['cluster_name'])

    # get data of open-falcon and statsd
    falcon_data, stats_data_gauge1, stats_data_timer1 = get_keys(health, traps1, data_time)  # getting health values
    falcon_data2, stats_data_gauge2, stats_data_timer2 = get_keys(node, traps2, data_time)  # getting stats values

    # converging of metrics
    falcon_data.extend(falcon_data2)
    stats_data_gauge = dict(stats_data_gauge1, **stats_data_gauge2)
    put_data_timer = dict(stats_data_timer1, **stats_data_timer2)
    stats_data_timer = timer_to_gauge(put_data_timer)
    if q.empty():
        q.put(put_data_timer)
    finally_data_timer = timer_to_timer_rate(stats_data_timer)

    try:
        # send metrics to open-falcon
        url = load_falcon_conf(OPEN_FALCON)
        send_to_falcon(url, falcon_data)
    except Exception as e:
        es_logger_out.error(e)
        print_exc()
    finally:
        # send metrics to StatsD
        send_to_statsd(statsd_client, stats_data_gauge, gauge=True)
        send_to_statsd(statsd_client, finally_data_timer, timer=True)
        es_logger_out.info("Delivery %d metrics success! \n", len(falcon_data))

        # write_log(res.text, len(falcon_data))


if __name__ == "__main__":
    myDaemon = MyDaemon(pidfile=pidfile,
                        # stdout=stdout,
                        stderr=stderr)
    args = sys.argv
    if len(args) == 2:
        if 'start' == args[1]:
            myDaemon.start()
        elif 'stop' == args[1]:
            myDaemon.stop()
        elif 'restart' == args[1]:
            myDaemon.restart()
        else:
            es_logger_out.error('*** Unknown command')
            sys.exit(2)
        sys.exit(0)
    else:
        print('Usage: {} start|stop|restart'.format(args[0]))
        sys.exit(2)
