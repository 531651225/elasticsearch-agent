#!/usr/bin/env python
# encoding: utf-8

"""
Author: Rosen
Mail: rosenluov@gmail.com
File: es-agent.py
Created Time: 12/21/16 14:34
"""

from __future__ import print_function

import json
import logging
import os
import sys
import time
from multiprocessing import Process, Queue
from traceback import print_exc

import requests
import statsd

from conf.settings import (
    traps1,
    traps2,
    GAUGE,
    COUNTER,
    pidfile,
    stderr,
    HOSTNAME,
    IP,
    PORT,
    STATSD_FILE,
    OPEN_FALCON,
    ES_FILE,
    SEC_METRIC
)
from utils.common import load_yaml_data
from utils.daemonize import Daemon

"""
    The ElasticSearch-agent collects state information by
    calling the ElasticSearch API and sends it to StatsD and open-falcon.
"""

es_logger_out = logging.getLogger('')

q = Queue(10)


def load_statsd_conf(filename=None):
    data = load_yaml_data(filename)
    host = data.get('host', '')
    port = data.get('port', )
    return host, port


def load_falcon_conf(filename=None):
    data = load_yaml_data(filename)
    url = data.get('url', '')
    return url


def es_data(endpoint, metric, timestamp, value, counter_type, tags):
    structure = {
        'endpoint': endpoint,
        'metric': metric,
        'timestamp': timestamp,
        'step': 10,
        'value': value,
        'counterType': counter_type,
        'tags': tags
    }
    return structure


# read specified keys from json data
def get_keys(stats, traps, ts):
    stats_data_gauge = {}
    stats_data_timer = {}
    tags = ""
    falcon_data = []

    for key in traps:
        if key == 'status':
            value = stats.get(key, '')
            if value == 'green':
                stats[key] = 1
            elif value == 'yellow':
                stats[key] = 2
            elif value == 'red':
                stats[key] = 0

        c = key.split('.')
        s = stats
        while len(c):
            s = s.get(c.pop(0), {})

        if s == {}:
            continue

        metric = 'es.' + key
        if key in GAUGE:
            falcon_data.append(es_data(HOSTNAME, metric, ts, s, 'GAUGE', tags))
            stats_data_gauge[key] = s
        elif key in COUNTER:
            falcon_data.append(es_data(HOSTNAME, metric, ts, s, 'COUNTER', tags))
            stats_data_timer[key] = s

    return falcon_data, stats_data_gauge, stats_data_timer


class MyDaemon(Daemon):
    @staticmethod
    def run():
        es_logger_out.info("Daemon started with pid %d! \n", os.getpid())
        while True:
            if int(time.time()) % 10 == 0:
                p = Process(target=main, args=(int(time.time()),))
                p.start()
                p.join()
            time.sleep(1)


def send_to_falcon(url=None, data=None):
    if data and url:
        res = requests.post(url, data=json.dumps(data))
        return res


def send_to_statsd(statsd_client=None, data=None):
    try:
        if data and statsd_client:
            for k, v in data.items():
                metric = HOSTNAME + '.' + k
                statsd_client.gauge(metric, v)

    except Exception as e:
        es_logger_out.error(e)
        print_exc()


def timer_to_gauge(data=None):
    counter_stats_data = {}
    if not q.empty():
        es_logger_out.info('Get a message from the Queue.')
        old_stats_data = q.get()
        for k in data:
            counter_stats_data[k] = round((float(data[k]) - float(old_stats_data[k])) / 10, 2)
    else:
        es_logger_out.error('Queue is empty!')
    return counter_stats_data


def timer_to_timer_rate(data=None):
    sec_data = {}
    if data:
        for k, v in SEC_METRIC.items():
            key = k + '_sec'
            try:
                sec_data[key] = data[k] / data[v]
            except ZeroDivisionError:
                sec_data[key] = 0
        statsd_data_timer = dict(data, **sec_data)
        return statsd_data_timer
    else:
        es_logger_out.info('No timers data.')


def indices_total(data=None):
    indices = {}
    if data:
        indices['indices_total'] = data['indices']['count']
    return indices


def health_result(ip, port):
    res = requests.get("http://{ip}:{port}/_cluster/health".format(ip=ip, port=port), timeout=10)
    health = res.json()
    return health


def node_result(ip, port):
    res = requests.get("http://{ip}:{port}/_nodes/_local/stats?all=true".format(ip=ip, port=port), timeout=10)
    node = res.json()
    return node


def indices_result(ip, port):
    res = requests.get("http://{ip}:{port}/_cluster/stats?all=true".format(ip=ip, port=port),
                       timeout=10)
    indices = res.json()
    return indices


def judge_role():
    data = load_yaml_data(ES_FILE)
    has_master = data.get('node.master', '')
    cluster_name = data.get('cluster.name', '')
    return has_master, cluster_name


def main(data_time):
    node = {}
    indices = {}
    falcon_data = []
    stats_data_gauge1 = {}
    stats_data_timer1 = {}
    try:
        data_time = data_time

        # load json data
        has_master, cluster_name = judge_role()
        if has_master or not cluster_name:
            health = health_result(IP, PORT)
            # only the master to obtains health values
            falcon_data, stats_data_gauge1, stats_data_timer1 = get_keys(health, traps1, data_time)
            if data_time % 60 == 0:
                cluster_stats = indices_result(IP, PORT)
                indices = indices_total(cluster_stats)

        node_stats = node_result(IP, PORT)

        # only for current node
        for node_id in node_stats.get('nodes', {}).keys():
            if node_stats['nodes'][node_id]['host'].startswith(IP):
                node = node_stats['nodes'][node_id]
                if len(sys.argv) == 1:
                    es_logger_out.error("node found")

        # getting stats values
        falcon_data2, stats_data_gauge2, stats_data_timer2 = get_keys(node, traps2, data_time)

    except (requests.exceptions.ConnectTimeout,
            requests.exceptions.ReadTimeout,
            ) as e:
        es_logger_out.error(e)
        print_exc()
        sys.exit(1)

    except Exception as e:
        es_logger_out.error(str(e) + " and Unable to load JSON data!")
        print_exc()
        sys.exit(1)

    statsd_host, statsd_port = load_statsd_conf(STATSD_FILE)
    statsd_client = statsd.StatsClient(statsd_host, statsd_port, cluster_name)

    # converging of metrics
    falcon_data.extend(falcon_data2)
    stats_data_gauge = dict(stats_data_gauge1, **stats_data_gauge2)
    stats_data_gauge_append_indices = dict(stats_data_gauge, **indices)

    # use to calculate the difference
    put_data_timer = dict(stats_data_timer1, **stats_data_timer2)
    stats_data_timer = timer_to_gauge(put_data_timer)
    if q.empty():
        es_logger_out.info("Data has been put to the Queue!")
        q.put(put_data_timer)

    if stats_data_timer:
        # finally data
        finally_data_timer = timer_to_timer_rate(stats_data_timer)
        finally_data_statsd = stats_data_gauge_append_indices
        finally_data = dict(finally_data_statsd, **finally_data_timer)

        try:
            # send metrics to open-falcon
            url = load_falcon_conf(OPEN_FALCON)
            send_to_falcon(url, falcon_data)
        except Exception as e:
            es_logger_out.error(e)
            print_exc()
        finally:
            # send metrics to StatsD
            send_to_statsd(statsd_client, finally_data)
            es_logger_out.info("Delivery %d metrics success! \n", len(finally_data))


if __name__ == "__main__":
    myDaemon = MyDaemon(pidfile=pidfile,
                        # stdout=stdout,
                        stderr=stderr)
    args = sys.argv
    if len(args) == 2:
        if 'start' == args[1]:
            myDaemon.start()
        elif 'stop' == args[1]:
            myDaemon.stop()
        elif 'restart' == args[1]:
            myDaemon.restart()
        else:
            es_logger_out.error('*** Unknown command')
            sys.exit(2)
        sys.exit(0)
    else:
        print('Usage: {} start|stop|restart'.format(args[0]))
        sys.exit(2)
